{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fazal735/DL_A3/blob/main/DL_A3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW9jUy9HnQqZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, RNN, LSTM, GRU, SimpleRNN\n",
        "\n",
        "\n",
        "class TransliterationSeq2Seq(Model):\n",
        "    def __init__(self,\n",
        "                 input_vocab_size,\n",
        "                 target_vocab_size,\n",
        "                 embedding_dim,\n",
        "                 encoder_units,\n",
        "                 decoder_units,\n",
        "                 cell_type='lstm',\n",
        "                 encoder_layers=1,\n",
        "                 decoder_layers=1):\n",
        "        \"\"\"\n",
        "        Initialize the Seq2Seq model for transliteration.\n",
        "\n",
        "        Args:\n",
        "            input_vocab_size: Size of the input language vocabulary\n",
        "            target_vocab_size: Size of the target language vocabulary\n",
        "            embedding_dim: Dimension of character embeddings\n",
        "            encoder_units: Number of units in encoder cell\n",
        "            decoder_units: Number of units in decoder cell\n",
        "            cell_type: Type of RNN cell ('rnn', 'lstm', or 'gru')\n",
        "            encoder_layers: Number of layers in the encoder\n",
        "            decoder_layers: Number of layers in the decoder\n",
        "        \"\"\"\n",
        "        super(TransliterationSeq2Seq, self).__init__()\n",
        "\n",
        "        # Store model parameters\n",
        "        self.encoder_units = encoder_units\n",
        "        self.decoder_units = decoder_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "        self.target_vocab_size = target_vocab_size\n",
        "\n",
        "        # Create embeddings for input characters\n",
        "        self.embedding = Embedding(input_vocab_size, embedding_dim)\n",
        "\n",
        "        # Setup the cell type based on user preference\n",
        "        self.cell_type = cell_type.lower()\n",
        "        if self.cell_type == 'lstm':\n",
        "            rnn_cell = LSTM\n",
        "        elif self.cell_type == 'gru':\n",
        "            rnn_cell = GRU\n",
        "        elif self.cell_type == 'rnn':\n",
        "            rnn_cell = SimpleRNN\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported cell type: {cell_type}\")\n",
        "\n",
        "        # Create encoder layers\n",
        "        self.encoder_layers = []\n",
        "        for i in range(encoder_layers):\n",
        "            input_size = embedding_dim if i == 0 else encoder_units\n",
        "            return_sequences = (i < encoder_layers - 1)\n",
        "            self.encoder_layers.append(\n",
        "                rnn_cell(encoder_units,\n",
        "                         return_sequences=return_sequences,\n",
        "                         return_state=True,\n",
        "                         name=f'encoder_layer_{i+1}')\n",
        "            )\n",
        "\n",
        "        # Create decoder layers\n",
        "        self.decoder_layers = []\n",
        "        for i in range(decoder_layers):\n",
        "            input_size = embedding_dim if i == 0 else decoder_units\n",
        "            return_sequences = True\n",
        "            self.decoder_layers.append(\n",
        "                rnn_cell(decoder_units,\n",
        "                         return_sequences=return_sequences,\n",
        "                         return_state=True,\n",
        "                         name=f'decoder_layer_{i+1}')\n",
        "            )\n",
        "\n",
        "        # Output layer to convert decoder output to character probabilities\n",
        "        self.fc = Dense(target_vocab_size, activation='softmax')\n",
        "\n",
        "        if encoder_units != decoder_units:\n",
        "            if self.cell_type == 'lstm':\n",
        "                self.state_h_adapter = tf.keras.layers.Dense(decoder_units, name='state_h_adapter')\n",
        "                self.state_c_adapter = tf.keras.layers.Dense(decoder_units, name='state_c_adapter')\n",
        "            else:\n",
        "                self.state_adapter = tf.keras.layers.Dense(decoder_units, name='state_adapter')\n",
        "\n",
        "    def encode(self, input_seq):\n",
        "        \"\"\"\n",
        "        Encode the input sequence.\n",
        "\n",
        "        Args:\n",
        "            input_seq: Input sequence tensor of shape (batch_size, seq_length)\n",
        "\n",
        "        Returns:\n",
        "            encoder_outputs: Outputs from the encoder\n",
        "            encoder_states: Final states from the encoder (to initialize decoder)\n",
        "        \"\"\"\n",
        "        # Embed input sequence\n",
        "        x = self.embedding(input_seq)\n",
        "\n",
        "        # Process through encoder layers\n",
        "        encoder_states = []\n",
        "        for i, encoder_layer in enumerate(self.encoder_layers):\n",
        "            if i == 0:\n",
        "                outputs = x\n",
        "\n",
        "            if self.cell_type == 'lstm':\n",
        "                outputs, state_h, state_c = encoder_layer(outputs)\n",
        "                encoder_states.extend([state_h, state_c])\n",
        "            else:  # RNN or GRU\n",
        "                outputs, state = encoder_layer(outputs)\n",
        "                encoder_states.append(state)\n",
        "\n",
        "        return outputs, encoder_states\n",
        "\n",
        "    def adapt_encoder_states_for_decoder(self, encoder_states):\n",
        "        \"\"\"Adapt encoder states to be compatible with decoder dimensions\"\"\"\n",
        "        decoder_states = []\n",
        "\n",
        "        for state in encoder_states:\n",
        "            if self.cell_type == 'lstm':\n",
        "                state_h, state_c = state\n",
        "                if hasattr(self, 'state_h_adapter'):\n",
        "                    adapted_h = self.state_h_adapter(state_h)\n",
        "                    adapted_c = self.state_c_adapter(state_c)\n",
        "                    decoder_states.append((adapted_h, adapted_c))\n",
        "                else:\n",
        "                    decoder_states.append((state_h, state_c))\n",
        "            else:\n",
        "                if hasattr(self, 'state_adapter'):\n",
        "                    adapted_state = self.state_adapter(state)\n",
        "                    decoder_states.append(adapted_state)\n",
        "                else:\n",
        "                    decoder_states.append(state)\n",
        "\n",
        "        return decoder_states\n",
        "\n",
        "    def decode_step(self, x, states):\n",
        "        \"\"\"\n",
        "        Perform one decoding step.\n",
        "\n",
        "        Args:\n",
        "            x: Input character tensor of shape (batch_size, 1)\n",
        "            states: Previous states from the decoder\n",
        "\n",
        "        Returns:\n",
        "            output: Output probabilities\n",
        "            new_states: Updated states\n",
        "        \"\"\"\n",
        "        # Embed input character\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # Process through decoder layers\n",
        "        all_new_states = []\n",
        "        for i, decoder_layer in enumerate(self.decoder_layers):\n",
        "            if i == 0:\n",
        "                layer_input = x\n",
        "            else:\n",
        "                layer_input = outputs\n",
        "\n",
        "            # Extract the states for this layer\n",
        "            if self.cell_type == 'lstm':\n",
        "                layer_states = [states[i*2], states[i*2+1]]\n",
        "            else:  # RNN or GRU\n",
        "                layer_states = [states[i]]\n",
        "\n",
        "            # Process through the layer\n",
        "            if self.cell_type == 'lstm':\n",
        "                outputs, state_h, state_c = decoder_layer(layer_input, initial_state=layer_states)\n",
        "                all_new_states.extend([state_h, state_c])\n",
        "            else:  # RNN or GRU\n",
        "                outputs, state = decoder_layer(layer_input, initial_state=layer_states)\n",
        "                all_new_states.append(state)\n",
        "\n",
        "        # Generate output probabilities\n",
        "        output = self.fc(outputs)\n",
        "\n",
        "        return output, all_new_states\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"\n",
        "        Forward pass through the model.\n",
        "\n",
        "        Args:\n",
        "            inputs: Tuple of (input_seq, target_seq)\n",
        "            training: Whether the model is in training mode\n",
        "\n",
        "        Returns:\n",
        "            outputs: Sequence of output probabilities\n",
        "        \"\"\"\n",
        "        input_seq, target_seq = inputs\n",
        "\n",
        "        # Encode the input sequence\n",
        "        encoder_outputs, encoder_states = self.encode(input_seq)\n",
        "\n",
        "        # Initialize decoder states with encoder states\n",
        "        decoder_states = encoder_states\n",
        "\n",
        "        # Teacher forcing: feeding the target as the next input\n",
        "        decoder_inputs = target_seq[:, :-1]  # exclude last character\n",
        "\n",
        "        # Initialize list to store outputs\n",
        "        outputs = []\n",
        "\n",
        "        # Process each character in the target sequence\n",
        "        for t in range(decoder_inputs.shape[1]):\n",
        "            # Extract input for this timestep\n",
        "            decoder_input = decoder_inputs[:, t:t+1]\n",
        "\n",
        "            # Perform one decoding step\n",
        "            output, decoder_states = self.decode_step(decoder_input, decoder_states)\n",
        "\n",
        "            # Store output\n",
        "            outputs.append(output)\n",
        "\n",
        "        # Concatenate outputs along time axis\n",
        "        return tf.concat(outputs, axis=1)\n",
        "\n",
        "    def predict(self, input_seq, max_length=100, start_token=1, end_token=2):\n",
        "        \"\"\"\n",
        "        Generate a transliteration for an input sequence.\n",
        "\n",
        "        Args:\n",
        "            input_seq: Input sequence tensor of shape (batch_size, seq_length)\n",
        "            max_length: Maximum length of the output sequence\n",
        "            start_token: ID of the start token\n",
        "            end_token: ID of the end token\n",
        "\n",
        "        Returns:\n",
        "            outputs: Generated output sequence\n",
        "        \"\"\"\n",
        "        # Encode the input sequence\n",
        "        _, encoder_states = self.encode(input_seq)\n",
        "\n",
        "        # Initialize decoder states with encoder states\n",
        "        decoder_states = encoder_states\n",
        "\n",
        "        # Start with the start token\n",
        "        batch_size = input_seq.shape[0]\n",
        "        decoder_input = tf.ones((batch_size, 1), dtype=tf.int32) * start_token\n",
        "\n",
        "        # Initialize list to store outputs\n",
        "        outputs = []\n",
        "\n",
        "        # Generate characters until max_length or end token\n",
        "        for t in range(max_length):\n",
        "            # Perform one decoding step\n",
        "            output, decoder_states = self.decode_step(decoder_input, decoder_states)\n",
        "\n",
        "            # Get the most likely character\n",
        "            predicted_id = tf.argmax(output, axis=-1)\n",
        "\n",
        "            # Store output\n",
        "            outputs.append(predicted_id)\n",
        "\n",
        "            # Break if end token is predicted\n",
        "            if predicted_id == end_token:\n",
        "                break\n",
        "\n",
        "            # Use predicted ID as next input\n",
        "            decoder_input = predicted_id\n",
        "\n",
        "        # Concatenate outputs along time axis\n",
        "        return tf.concat(outputs, axis=1)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "def create_model(input_vocab_size=1000,\n",
        "                target_vocab_size=1000,\n",
        "                embedding_dim=256,\n",
        "                encoder_units=512,\n",
        "                decoder_units=512,\n",
        "                cell_type='lstm',\n",
        "                encoder_layers=1,\n",
        "                decoder_layers=1):\n",
        "    \"\"\"\n",
        "    Create and compile a transliteration model.\n",
        "\n",
        "    Args:\n",
        "        input_vocab_size: Size of the input vocabulary\n",
        "        target_vocab_size: Size of the target vocabulary\n",
        "        embedding_dim: Dimension of character embeddings\n",
        "        encoder_units: Number of units in encoder cell\n",
        "        decoder_units: Number of units in decoder cell\n",
        "        cell_type: Type of RNN cell ('rnn', 'lstm', or 'gru')\n",
        "        encoder_layers: Number of layers in the encoder\n",
        "        decoder_layers: Number of layers in the decoder\n",
        "\n",
        "    Returns:\n",
        "        model: Compiled transliteration model\n",
        "    \"\"\"\n",
        "    # Create inputs\n",
        "    input_seq = Input(shape=(None,), name='input_sequence')\n",
        "    target_seq = Input(shape=(None,), name='target_sequence')\n",
        "\n",
        "    # Create model\n",
        "    model = TransliterationSeq2Seq(\n",
        "        input_vocab_size=input_vocab_size,\n",
        "        target_vocab_size=target_vocab_size,\n",
        "        embedding_dim=embedding_dim,\n",
        "        encoder_units=encoder_units,\n",
        "        decoder_units=decoder_units,\n",
        "        cell_type=cell_type,\n",
        "        encoder_layers=encoder_layers,\n",
        "        decoder_layers=decoder_layers\n",
        "    )\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Training example\n",
        "def train_model(model, input_sequences, target_sequences, epochs=10, batch_size=64):\n",
        "    \"\"\"\n",
        "    Train the transliteration model.\n",
        "\n",
        "    Args:\n",
        "        model: Compiled transliteration model\n",
        "        input_sequences: Input sequences (Latin script)\n",
        "        target_sequences: Target sequences (Devanagari script)\n",
        "        epochs: Number of epochs to train\n",
        "        batch_size: Batch size for training\n",
        "\n",
        "    Returns:\n",
        "        history: Training history\n",
        "    \"\"\"\n",
        "    # Prepare target sequences for training (shifted by 1)\n",
        "    shifted_target_sequences = target_sequences[:, 1:]\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        [input_sequences, target_sequences],\n",
        "        shifted_target_sequences,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h19j_cRLtYZe",
        "outputId": "accd6fe0-e8fc-4e70-e595-ee1637be2668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: wandb 0.19.11\n",
            "Uninstalling wandb-0.19.11:\n",
            "  Successfully uninstalled wandb-0.19.11\n",
            "\u001b[33mWARNING: Skipping wandb-sdk as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping wandb-core as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip uninstall -y wandb\n",
        "!pip uninstall -y wandb-sdk\n",
        "!pip uninstall -y wandb-core\n",
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSyFN5X2wEL6",
        "outputId": "bd0c16e8-fee1-4cfe-c22d-895b4a22cccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Using cached wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.28.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Using cached wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
            "Installing collected packages: wandb\n",
            "Successfully installed wandb-0.19.11\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRh80Y_cDGDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d7eebc-c08e-4d81-833a-be820ac8dafb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import wandb\n",
        "# from wandb.keras import WandbCallback\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, RNN, LSTM, GRU, SimpleRNN\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYAp9zQkDMFa"
      },
      "outputs": [],
      "source": [
        "# Data loading and preprocessing\n",
        "\n",
        "\n",
        "def load_dakshina_data(language='ur', data_dir='/content/drive/MyDrive/dakshina_dataset_v1.0/'):\n",
        "\n",
        "    data_path = os.path.join(data_dir, language, 'lexicons')\n",
        "\n",
        "    train_file = os.path.join(data_path, f'{language}.translit.sampled.train.tsv')\n",
        "    dev_file = os.path.join(data_path, f'{language}.translit.sampled.dev.tsv')\n",
        "    test_file = os.path.join(data_path, f'{language}.translit.sampled.test.tsv')\n",
        "\n",
        "    train_data = pd.read_csv(train_file, sep='\\t', header=None, names=['native', 'latin','n'])\n",
        "    dev_data = pd.read_csv(dev_file, sep='\\t', header=None, names=['native', 'latin','n'])\n",
        "    test_data = pd.read_csv(test_file, sep='\\t', header=None, names=['native', 'latin','n'])\n",
        "\n",
        "\n",
        "    print(f\"Loaded {len(train_data)} training, {len(dev_data)} dev, and {len(test_data)} test examples.\")\n",
        "\n",
        "    return train_data, dev_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbQLy9sVDeGz"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def preprocess_data(train_data, dev_data, test_data):\n",
        "    \"\"\"\n",
        "    Preprocess the data: tokenize, create vocabulary, and convert to sequences.\n",
        "\n",
        "    Args:\n",
        "        train_data, dev_data, test_data: DataFrames with native and latin script pairs\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing preprocessed data and tokenizers\n",
        "    \"\"\"\n",
        "\n",
        "    print(train_data.head())\n",
        "\n",
        "    # Clean the 'latin' column: remove NaNs and convert all to strings\n",
        "    train_data['latin'] = train_data['latin'].astype(str).fillna('')\n",
        "\n",
        "    # Or, to be safer and remove completely invalid rows:\n",
        "    train_data = train_data.dropna(subset=['latin'])\n",
        "    train_data['latin'] = train_data['latin'].astype(str)\n",
        "\n",
        "\n",
        "    # Create character-level tokenizers\n",
        "    latin_tokenizer = Tokenizer(char_level=True)\n",
        "    native_tokenizer = Tokenizer(char_level=True)\n",
        "\n",
        "    # Fit tokenizers on training data\n",
        "    latin_tokenizer.fit_on_texts((train_data['latin']).tolist())\n",
        "    native_tokenizer.fit_on_texts((train_data['native']).tolist())\n",
        "\n",
        "    # Get vocabulary sizes\n",
        "    latin_vocab_size = len(latin_tokenizer.word_index) + 1  # +1 for padding\n",
        "    native_vocab_size = len(native_tokenizer.word_index) + 1  # +1 for padding\n",
        "\n",
        "    # Convert text to sequences\n",
        "    train_latin_seq = latin_tokenizer.texts_to_sequences(list(train_data['latin']))\n",
        "    train_native_seq = native_tokenizer.texts_to_sequences(list(train_data['native']))\n",
        "\n",
        "    dev_latin_seq = latin_tokenizer.texts_to_sequences(list(dev_data['latin']))\n",
        "    dev_native_seq = native_tokenizer.texts_to_sequences(list(dev_data['native']))\n",
        "\n",
        "    test_latin_seq = latin_tokenizer.texts_to_sequences(list(test_data['latin']))\n",
        "    test_native_seq = native_tokenizer.texts_to_sequences(list(test_data['native']))\n",
        "\n",
        "    # Find maximum sequence lengths\n",
        "    max_latin_len = max(max(len(seq) for seq in train_latin_seq),\n",
        "                        max(len(seq) for seq in dev_latin_seq),\n",
        "                        max(len(seq) for seq in test_latin_seq))\n",
        "\n",
        "    max_native_len = max(max(len(seq) for seq in train_native_seq),\n",
        "                         max(len(seq) for seq in dev_native_seq),\n",
        "                         max(len(seq) for seq in test_native_seq))\n",
        "\n",
        "    # Add 2 for start and end tokens\n",
        "    max_latin_len += 2\n",
        "    max_native_len += 2\n",
        "\n",
        "    # Add start (<s>) and end (</s>) tokens to target sequences\n",
        "    start_token = native_vocab_size  # Use vocab_size as start token\n",
        "    end_token = native_vocab_size + 1  # Use vocab_size+1 as end token\n",
        "    native_vocab_size += 2  # Increase vocab size for start and end tokens\n",
        "\n",
        "    # Add start and end tokens to native sequences\n",
        "    def add_start_end(sequences, max_len, start_token, end_token):\n",
        "        new_sequences = []\n",
        "        for seq in sequences:\n",
        "            new_seq = [start_token] + seq + [end_token]\n",
        "            new_sequences.append(new_seq)\n",
        "        return pad_sequences(new_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "    # Pad sequences\n",
        "    train_latin_padded = pad_sequences(train_latin_seq, maxlen=max_latin_len, padding='post')\n",
        "    train_native_padded = add_start_end(train_native_seq, max_native_len, start_token, end_token)\n",
        "\n",
        "    dev_latin_padded = pad_sequences(dev_latin_seq, maxlen=max_latin_len, padding='post')\n",
        "    dev_native_padded = add_start_end(dev_native_seq, max_native_len, start_token, end_token)\n",
        "\n",
        "    test_latin_padded = pad_sequences(test_latin_seq, maxlen=max_latin_len, padding='post')\n",
        "    test_native_padded = add_start_end(test_native_seq, max_native_len, start_token, end_token)\n",
        "\n",
        "    # Target for teacher forcing (shifted right by one position)\n",
        "    train_native_target = train_native_padded[:, 1:]  # Remove start token\n",
        "    dev_native_target = dev_native_padded[:, 1:]  # Remove start token\n",
        "\n",
        "    return {\n",
        "        'latin_tokenizer': latin_tokenizer,\n",
        "        'native_tokenizer': native_tokenizer,\n",
        "        'latin_vocab_size': latin_vocab_size,\n",
        "        'native_vocab_size': native_vocab_size,\n",
        "        'max_latin_len': max_latin_len,\n",
        "        'max_native_len': max_native_len,\n",
        "        'start_token': start_token,\n",
        "        'end_token': end_token,\n",
        "        'train_latin': train_latin_padded,\n",
        "        'train_native': train_native_padded,\n",
        "        'train_native_target': train_native_target,\n",
        "        'dev_latin': dev_latin_padded,\n",
        "        'dev_native': dev_native_padded,\n",
        "        'dev_native_target': dev_native_target,\n",
        "        'test_latin': test_latin_padded,\n",
        "        'test_native': test_native_padded\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQtxj-j5pfku"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7dQfWl61cs7"
      },
      "outputs": [],
      "source": [
        "class TransliterationSeq2Seq(Model):\n",
        "    def __init__(self,\n",
        "                 input_vocab_size,\n",
        "                 target_vocab_size,\n",
        "                 embedding_dim,\n",
        "                 decoder_hidden_dim,\n",
        "                 encoder_units,\n",
        "                 decoder_units,\n",
        "                 cell_type='lstm',\n",
        "                 encoder_layers=1,\n",
        "                 decoder_layers=1,\n",
        "                 dropout_rate=0.0,\n",
        "                 recurrent_dropout_rate=0.0):\n",
        "        \"\"\"\n",
        "        Initialize the Seq2Seq model for transliteration with dropout support.\n",
        "\n",
        "        Args:\n",
        "            input_vocab_size: Size of the input language vocabulary\n",
        "            target_vocab_size: Size of the target language vocabulary\n",
        "            embedding_dim: Dimension of character embeddings\n",
        "            decoder_hidden_dim: Hidden dimension for decoder\n",
        "            encoder_units: Number of units in encoder cell\n",
        "            decoder_units: Number of units in decoder cell\n",
        "            cell_type: Type of RNN cell ('rnn', 'lstm', or 'gru')\n",
        "            encoder_layers: Number of layers in the encoder\n",
        "            decoder_layers: Number of layers in the decoder\n",
        "            dropout_rate: Dropout rate after RNN layers\n",
        "            recurrent_dropout_rate: Dropout rate inside RNN cells\n",
        "        \"\"\"\n",
        "        super(TransliterationSeq2Seq, self).__init__()\n",
        "\n",
        "        # Store model parameters\n",
        "        self.encoder_units = encoder_units\n",
        "        self.decoder_units = decoder_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.decoder_hidden_dim = decoder_hidden_dim\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "        self.target_vocab_size = target_vocab_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.recurrent_dropout_rate = recurrent_dropout_rate\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.encoder_layers = encoder_layers\n",
        "        self.decoder_layers = decoder_layers\n",
        "\n",
        "        # Create embeddings - only define once\n",
        "        self.input_embedding = Embedding(input_vocab_size, embedding_dim)\n",
        "        self.target_embedding = Embedding(target_vocab_size, embedding_dim)\n",
        "        self.embedding_projection = Dense(decoder_hidden_dim)\n",
        "\n",
        "        # Setup the cell type based on user preference\n",
        "        rnn_kwargs = {'return_state': True}\n",
        "\n",
        "        # Add recurrent dropout if specified\n",
        "        if recurrent_dropout_rate > 0:\n",
        "            rnn_kwargs['recurrent_dropout'] = recurrent_dropout_rate\n",
        "\n",
        "        if self.cell_type == 'lstm':\n",
        "            rnn_cell = LSTM\n",
        "        elif self.cell_type == 'gru':\n",
        "            rnn_cell = GRU\n",
        "        elif self.cell_type == 'rnn':\n",
        "            rnn_cell = SimpleRNN\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported cell type: {cell_type}\")\n",
        "\n",
        "        # Create encoder RNN layers\n",
        "        self.encoder_rnn_layers = []\n",
        "        for i in range(encoder_layers):\n",
        "            return_sequences = (i < encoder_layers - 1)\n",
        "            layer_kwargs = rnn_kwargs.copy()\n",
        "            layer_kwargs['return_sequences'] = return_sequences\n",
        "            layer_kwargs['name'] = f'encoder_layer_{i+1}'\n",
        "\n",
        "            self.encoder_rnn_layers.append(rnn_cell(encoder_units, **layer_kwargs))\n",
        "\n",
        "        # Create encoder dropout layers (separate from RNN layers)\n",
        "        self.encoder_dropout_layers = []\n",
        "        for i in range(encoder_layers - 1):  # No dropout after last layer\n",
        "            if dropout_rate > 0:\n",
        "                self.encoder_dropout_layers.append(Dropout(dropout_rate))\n",
        "            else:\n",
        "                self.encoder_dropout_layers.append(None)\n",
        "\n",
        "        # Create decoder RNN layers\n",
        "        self.decoder_rnn_layers = []\n",
        "        for i in range(decoder_layers):\n",
        "            return_sequences = True\n",
        "            layer_kwargs = rnn_kwargs.copy()\n",
        "            layer_kwargs['return_sequences'] = return_sequences\n",
        "            layer_kwargs['name'] = f'decoder_layer_{i+1}'\n",
        "\n",
        "            self.decoder_rnn_layers.append(rnn_cell(decoder_units, **layer_kwargs))\n",
        "\n",
        "        # Create decoder dropout layers\n",
        "        self.decoder_dropout_layers = []\n",
        "        for i in range(decoder_layers - 1):  # No dropout after last layer\n",
        "            if dropout_rate > 0:\n",
        "                self.decoder_dropout_layers.append(Dropout(dropout_rate))\n",
        "            else:\n",
        "                self.decoder_dropout_layers.append(None)\n",
        "\n",
        "        # Final dropout before output layer\n",
        "        self.final_dropout = Dropout(dropout_rate) if dropout_rate > 0 else None\n",
        "\n",
        "        # Output layer to convert decoder output to character probabilities\n",
        "        self.fc = Dense(target_vocab_size, activation='softmax')\n",
        "\n",
        "        # Add state adapters if encoder and decoder dimensions don't match\n",
        "        if encoder_units != decoder_units:\n",
        "            if self.cell_type == 'lstm':\n",
        "                self.state_h_adapter = Dense(decoder_units, name='state_h_adapter')\n",
        "                self.state_c_adapter = Dense(decoder_units, name='state_c_adapter')\n",
        "            else:\n",
        "                self.state_adapter = Dense(decoder_units, name='state_adapter')\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        Build the model with the given input shape.\n",
        "\n",
        "        Args:\n",
        "            input_shape: Shape of input tensors\n",
        "        \"\"\"\n",
        "        # Just call the parent build method\n",
        "        super(TransliterationSeq2Seq, self).build(input_shape)\n",
        "\n",
        "    def encode(self, input_seq):\n",
        "        \"\"\"\n",
        "        Encode the input sequence.\n",
        "\n",
        "        Args:\n",
        "            input_seq: Input sequence tensor of shape (batch_size, seq_length)\n",
        "\n",
        "        Returns:\n",
        "            encoder_outputs: Outputs from the encoder\n",
        "            encoder_states: Final states from the encoder (to initialize decoder)\n",
        "        \"\"\"\n",
        "        # Embed input sequence\n",
        "        x = self.input_embedding(input_seq)\n",
        "\n",
        "        # Process through encoder layers\n",
        "        encoder_states = []\n",
        "\n",
        "        # Track the current layer output\n",
        "        layer_output = x\n",
        "\n",
        "        # Process through each encoder RNN layer\n",
        "        for i, rnn_layer in enumerate(self.encoder_rnn_layers):\n",
        "            # Apply RNN layer\n",
        "            if self.cell_type == 'lstm':\n",
        "                layer_output, state_h, state_c = rnn_layer(layer_output)\n",
        "                encoder_states.extend([state_h, state_c])\n",
        "            else:  # RNN or GRU\n",
        "                layer_output, state = rnn_layer(layer_output)\n",
        "                encoder_states.append(state)\n",
        "\n",
        "            # Apply dropout if needed and not the last layer\n",
        "            if i < len(self.encoder_dropout_layers) and self.encoder_dropout_layers[i] is not None:\n",
        "                layer_output = self.encoder_dropout_layers[i](layer_output)\n",
        "\n",
        "        return layer_output, encoder_states\n",
        "\n",
        "    def adapt_encoder_states_for_decoder(self, encoder_states):\n",
        "        \"\"\"\n",
        "        Adapt encoder states to be compatible with decoder dimensions.\n",
        "\n",
        "        Args:\n",
        "            encoder_states: List of encoder states\n",
        "\n",
        "        Returns:\n",
        "            decoder_states: List of adapted states for decoder\n",
        "        \"\"\"\n",
        "        decoder_states = []\n",
        "\n",
        "        if self.cell_type == 'lstm':\n",
        "            # For LSTM, we have pairs of states (h, c)\n",
        "            for i in range(0, len(encoder_states), 2):\n",
        "                state_h = encoder_states[i]\n",
        "                state_c = encoder_states[i+1]\n",
        "\n",
        "                # Apply adapters if dimensions don't match\n",
        "                if hasattr(self, 'state_h_adapter'):\n",
        "                    state_h = self.state_h_adapter(state_h)\n",
        "                    state_c = self.state_c_adapter(state_c)\n",
        "\n",
        "                decoder_states.append(state_h)\n",
        "                decoder_states.append(state_c)\n",
        "        else:\n",
        "            # For GRU or RNN, we have single states\n",
        "            for state in encoder_states:\n",
        "                if hasattr(self, 'state_adapter'):\n",
        "                    state = self.state_adapter(state)\n",
        "                decoder_states.append(state)\n",
        "\n",
        "        return decoder_states\n",
        "\n",
        "    def decode_step(self, x, states, training=None):\n",
        "        \"\"\"\n",
        "        Perform one decoding step.\n",
        "\n",
        "        Args:\n",
        "            x: Input character tensor of shape (batch_size, 1)\n",
        "            states: Previous states from the decoder\n",
        "            training: Whether in training mode or not\n",
        "\n",
        "        Returns:\n",
        "            output: Output probabilities\n",
        "            new_states: Updated states\n",
        "        \"\"\"\n",
        "        # Embed input character\n",
        "        x = self.target_embedding(x)\n",
        "        x = self.embedding_projection(x)\n",
        "\n",
        "        # Process through decoder layers\n",
        "        all_new_states = []\n",
        "        layer_output = x\n",
        "\n",
        "        # Track which state to use for each RNN layer\n",
        "        state_idx = 0\n",
        "\n",
        "        for i, rnn_layer in enumerate(self.decoder_rnn_layers):\n",
        "            if self.cell_type == 'lstm':\n",
        "                        if state_idx + 1 < len(states):\n",
        "                                    layer_states = [states[state_idx], states[state_idx + 1]]\n",
        "                        else:\n",
        "                                    # Fallback to zero state\n",
        "                                    batch_size = tf.shape(layer_output)[0]\n",
        "                                    hidden_size = rnn_layer.units\n",
        "                                    layer_states = [tf.zeros((batch_size, hidden_size)), tf.zeros((batch_size, hidden_size))]\n",
        "                        state_idx += 2\n",
        "            else:\n",
        "                        if state_idx < len(states):\n",
        "                                    layer_states = [states[state_idx]]\n",
        "                        else:\n",
        "                                    batch_size = tf.shape(layer_output)[0]\n",
        "                                    hidden_size = rnn_layer.units\n",
        "                                    layer_states = [tf.zeros((batch_size, hidden_size))]\n",
        "                        state_idx += 1\n",
        "\n",
        "            # Process through RNN layer\n",
        "            if self.cell_type == 'lstm':\n",
        "                        layer_output, state_h, state_c = rnn_layer(layer_output, initial_state=layer_states)\n",
        "                        all_new_states.extend([state_h, state_c])\n",
        "            else:\n",
        "                        layer_output, state = rnn_layer(layer_output, initial_state=layer_states)\n",
        "                        all_new_states.append(state)\n",
        "\n",
        "            # Dropout if not last layer\n",
        "            if i < len(self.decoder_dropout_layers) and self.decoder_dropout_layers[i] is not None:\n",
        "                        layer_output = self.decoder_dropout_layers[i](layer_output, training=training)\n",
        "\n",
        "\n",
        "        # Apply final dropout if specified\n",
        "        if self.final_dropout is not None:\n",
        "            layer_output = self.final_dropout(layer_output, training=training)\n",
        "\n",
        "        # Generate output probabilities\n",
        "        output = self.fc(layer_output)\n",
        "\n",
        "        return output, all_new_states\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"\n",
        "        Forward pass through the model.\n",
        "\n",
        "        Args:\n",
        "            inputs: Tuple of (input_seq, target_seq)\n",
        "            training: Whether the model is in training mode\n",
        "\n",
        "        Returns:\n",
        "            outputs: Sequence of output probabilities\n",
        "        \"\"\"\n",
        "        input_seq, target_seq = inputs\n",
        "\n",
        "        # Encode the input sequence\n",
        "        encoder_outputs, encoder_states = self.encode(input_seq,training=training)\n",
        "\n",
        "        # Initialize decoder states with adapted encoder states if needed\n",
        "        if self.encoder_units != self.decoder_units:\n",
        "            decoder_states = self.adapt_encoder_states_for_decoder(encoder_states)\n",
        "        else:\n",
        "            decoder_states = encoder_states\n",
        "\n",
        "        # Get decoder inputs (all tokens except the last one which is the target)\n",
        "        decoder_inputs = target_seq[:, :-1]\n",
        "\n",
        "        # Replace the loop with a TensorArray-based approach\n",
        "        batch_size = tf.shape(decoder_inputs)[0]\n",
        "        seq_length = tf.shape(decoder_inputs)[1]\n",
        "\n",
        "        # Initialize output TensorArray\n",
        "        outputs_ta = tf.TensorArray(dtype=tf.float32, size=seq_length)\n",
        "\n",
        "        # Initial time step\n",
        "        time = tf.constant(0)\n",
        "\n",
        "        # Create a while loop condition function\n",
        "        def condition(time, outputs_ta, decoder_states):\n",
        "            return time < seq_length\n",
        "\n",
        "        # Create a while loop body function\n",
        "        def body(time, outputs_ta, decoder_states):\n",
        "            # Get input for this timestep\n",
        "            decoder_input = tf.expand_dims(decoder_inputs[:, time], axis=1)\n",
        "\n",
        "            # Perform decoding step\n",
        "            output, decoder_states = self.decode_step(decoder_input, decoder_states, training=training)\n",
        "\n",
        "            # Write output to TensorArray\n",
        "            outputs_ta = outputs_ta.write(time, output[:, 0])\n",
        "\n",
        "            # Increment time\n",
        "            return time + 1, outputs_ta, decoder_states\n",
        "\n",
        "        # Run the while loop\n",
        "        _, outputs_ta, _ = tf.while_loop(\n",
        "            condition,\n",
        "            body,\n",
        "            [time, outputs_ta, decoder_states]\n",
        "        )\n",
        "\n",
        "        # Stack all outputs\n",
        "        outputs = outputs_ta.stack()\n",
        "\n",
        "        # Transpose to get [batch_size, seq_length, vocab_size]\n",
        "        outputs = tf.transpose(outputs, [1, 0, 2])\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def beam_search_decode(self, input_seq, max_length, beam_size=3, start_token=None, end_token=None):\n",
        "        \"\"\"\n",
        "        Generate a transliteration using beam search.\n",
        "\n",
        "        Args:\n",
        "            input_seq: Input sequence tensor of shape (batch_size, seq_length)\n",
        "            max_length: Maximum length of the output sequence\n",
        "            beam_size: Number of beams to track\n",
        "            start_token: ID of the start token\n",
        "            end_token: ID of the end token\n",
        "\n",
        "        Returns:\n",
        "            best_sequences: List of best sequences found (one per input sequence)\n",
        "        \"\"\"\n",
        "        batch_size = tf.shape(input_seq)[0]\n",
        "\n",
        "        # Default tokens if not provided\n",
        "        if start_token is None:\n",
        "            start_token = self.target_vocab_size - 2\n",
        "        if end_token is None:\n",
        "            end_token = self.target_vocab_size - 1\n",
        "\n",
        "        # Encode input sequence\n",
        "        _, encoder_states = self.encode(input_seq)\n",
        "\n",
        "        # Adapt encoder states for decoder if needed\n",
        "        if self.encoder_units != self.decoder_units:\n",
        "            decoder_states = self.adapt_encoder_states_for_decoder(encoder_states)\n",
        "        else:\n",
        "            decoder_states = encoder_states\n",
        "\n",
        "        # Process each input sequence separately (beam search isn't batch-friendly)\n",
        "        best_sequences = []\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            # Extract states for this batch item\n",
        "            if self.cell_type == 'lstm':\n",
        "                batch_states = []\n",
        "                for i in range(0, len(decoder_states), 2):\n",
        "                    batch_states.append(decoder_states[i][b:b+1])\n",
        "                    batch_states.append(decoder_states[i+1][b:b+1])\n",
        "            else:\n",
        "                batch_states = [state[b:b+1] for state in decoder_states]\n",
        "\n",
        "            # Initialize beam with start token\n",
        "            beams = [(0.0, [start_token], batch_states)]\n",
        "            complete_beams = []\n",
        "\n",
        "            # Generate sequence\n",
        "            for t in range(max_length):\n",
        "                new_beams = []\n",
        "\n",
        "                # Process each beam\n",
        "                for score, sequence, states in beams:\n",
        "                    # Check if sequence is complete\n",
        "                    if sequence[-1] == end_token:\n",
        "                        complete_beams.append((score, sequence))\n",
        "                        continue\n",
        "\n",
        "                    # Get next token predictions\n",
        "                    decoder_input = tf.constant([[sequence[-1]]], dtype=tf.int32)\n",
        "                    output, new_states = self.decode_step(decoder_input, states)\n",
        "\n",
        "                    # Get top k predictions\n",
        "                    log_probs = tf.math.log(output[0, 0])\n",
        "                    top_k_probs, top_k_indices = tf.math.top_k(log_probs, k=beam_size)\n",
        "\n",
        "                    # Create new beams\n",
        "                    for i in range(beam_size):\n",
        "                        new_score = score + top_k_probs[i].numpy()\n",
        "                        new_sequence = sequence + [top_k_indices[i].numpy()]\n",
        "                        new_beams.append((new_score, new_sequence, new_states))\n",
        "\n",
        "                # Keep only the best beams\n",
        "                beams = sorted(new_beams, key=lambda x: x[0], reverse=True)[:beam_size]\n",
        "\n",
        "                # Early stopping if all beams are complete\n",
        "                if all(beam[1][-1] == end_token for beam in beams):\n",
        "                    complete_beams.extend(beams)\n",
        "                    break\n",
        "\n",
        "            # Add incomplete beams to complete ones\n",
        "            complete_beams.extend([(score, sequence) for score, sequence, _ in beams if sequence[-1] != end_token])\n",
        "\n",
        "            # Sort and select the best sequence\n",
        "            if complete_beams:\n",
        "                best_sequence = sorted(complete_beams, key=lambda x: x[0], reverse=True)[0][1]\n",
        "                # Remove start and end tokens\n",
        "                if best_sequence[-1] == end_token:\n",
        "                    best_sequence = best_sequence[1:-1]\n",
        "                else:\n",
        "                    best_sequence = best_sequence[1:]\n",
        "            else:\n",
        "                best_sequence = []\n",
        "\n",
        "            best_sequences.append(best_sequence)\n",
        "\n",
        "        return best_sequences\n",
        "\n",
        "# Decoding and evaluation functions - keep these unchanged\n",
        "def decode_sequences(model, sequences, start_token, end_token, max_length, beam_size=1):\n",
        "    \"\"\"\n",
        "    Decode sequences using the model.\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        sequences: Input sequences to decode\n",
        "        start_token, end_token: Tokens to mark sequence start/end\n",
        "        max_length: Maximum output sequence length\n",
        "        beam_size: Beam size for beam search (1 = greedy)\n",
        "\n",
        "    Returns:\n",
        "        predicted_sequences: List of predicted token sequences\n",
        "    \"\"\"\n",
        "    if beam_size > 1:\n",
        "        return model.beam_search_decode(\n",
        "            sequences,\n",
        "            max_length=max_length,\n",
        "            beam_size=beam_size,\n",
        "            start_token=start_token,\n",
        "            end_token=end_token\n",
        "        )\n",
        "    else:\n",
        "        # Initialize with start token\n",
        "        batch_size = sequences.shape[0]\n",
        "        current_tokens = tf.ones((batch_size, 1), dtype=tf.int32) * start_token\n",
        "        predicted_sequences = []\n",
        "\n",
        "        # Encode input\n",
        "        _, encoder_states = model.encode(sequences)\n",
        "        decoder_states = encoder_states\n",
        "\n",
        "        # Generate tokens one by one\n",
        "        for t in range(max_length):\n",
        "            # Predict next token\n",
        "            output, decoder_states = model.decode_step(current_tokens, decoder_states)\n",
        "            predicted_token = tf.argmax(output, axis=-1)\n",
        "\n",
        "            # Store prediction\n",
        "            predicted_sequences.append(predicted_token)\n",
        "\n",
        "            # Check for end tokens\n",
        "            if tf.reduce_all(predicted_token == end_token):\n",
        "                break\n",
        "\n",
        "            # Update current token\n",
        "            current_tokens = predicted_token\n",
        "\n",
        "        # Concatenate and convert to list\n",
        "        predicted_sequences = tf.concat(predicted_sequences, axis=1).numpy()\n",
        "\n",
        "        # Remove end tokens and convert to list\n",
        "        result = []\n",
        "        for seq in predicted_sequences:\n",
        "            # Find position of end token\n",
        "            try:\n",
        "                end_pos = list(seq).index(end_token)\n",
        "                result.append(list(seq[:end_pos]))\n",
        "            except ValueError:\n",
        "                # No end token found\n",
        "                result.append(list(seq))\n",
        "\n",
        "        return result\n",
        "\n",
        "def calculate_accuracy(true_seqs, pred_seqs):\n",
        "    \"\"\"\n",
        "    Calculate character and word accuracy between true and predicted sequences.\n",
        "\n",
        "    Args:\n",
        "        true_seqs: List of true sequences\n",
        "        pred_seqs: List of predicted sequences\n",
        "\n",
        "    Returns:\n",
        "        Dict with character and word level accuracy\n",
        "    \"\"\"\n",
        "    char_correct = 0\n",
        "    char_total = 0\n",
        "    word_correct = 0\n",
        "    word_total = len(true_seqs)\n",
        "\n",
        "    for true_seq, pred_seq in zip(true_seqs, pred_seqs):\n",
        "        # Word is correct if all characters match\n",
        "        word_is_correct = True\n",
        "\n",
        "        # Count character matches\n",
        "        for i in range(min(len(true_seq), len(pred_seq))):\n",
        "            if true_seq[i] == pred_seq[i]:\n",
        "                char_correct += 1\n",
        "            else:\n",
        "                word_is_correct = False\n",
        "\n",
        "        # Add extra characters as errors\n",
        "        if len(true_seq) != len(pred_seq):\n",
        "            word_is_correct = False\n",
        "\n",
        "        # Count total characters\n",
        "        char_total += max(len(true_seq), len(pred_seq))\n",
        "\n",
        "        # Update word accuracy\n",
        "        if word_is_correct:\n",
        "            word_correct += 1\n",
        "\n",
        "    return {\n",
        "        'char_accuracy': char_correct / char_total if char_total > 0 else 0,\n",
        "        'word_accuracy': word_correct / word_total if word_total > 0 else 0\n",
        "    }\n",
        "\n",
        "def tokens_to_text(sequences, tokenizer):\n",
        "    \"\"\"\n",
        "    Convert token sequences back to text.\n",
        "\n",
        "    Args:\n",
        "        sequences: List of token sequences\n",
        "        tokenizer: Keras tokenizer\n",
        "\n",
        "    Returns:\n",
        "        List of text sequences\n",
        "    \"\"\"\n",
        "    # Reverse the word index\n",
        "    index_word = {v: k for k, v in tokenizer.word_index.items()}\n",
        "\n",
        "    # Convert sequences to text\n",
        "    texts = []\n",
        "    for seq in sequences:\n",
        "        text = ''.join(index_word.get(token, '') for token in seq if token in index_word)\n",
        "        texts.append(text)\n",
        "\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HD_ONk_wqFNr",
        "outputId": "16357e60-0ac1-4d83-c641-ec18e1f9acfa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: htolktf9\n",
            "Sweep URL: https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: js1cdtwu with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_hidden_dim: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_units: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_decoder_units_pair: {'decoder_units': 256, 'encoder_units': 256}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_units: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrent_dropout_rate: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmfazal735\u001b[0m (\u001b[33mmfazal735-iit-madras-foundation\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250519_025537-js1cdtwu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/js1cdtwu' target=\"_blank\">denim-sweep-1</a></strong> to <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/js1cdtwu' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/js1cdtwu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 106260 training, 10424 dev, and 10517 test examples.\n",
            "  native latin  n\n",
            "0     آؤ   aao  3\n",
            "1     آؤ  aaoo  1\n",
            "2     آؤ   aau  1\n",
            "3     آؤ   aaw  1\n",
            "4     آؤ  aawo  1\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">denim-sweep-1</strong> at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/js1cdtwu' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/js1cdtwu</a><br> View project at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250519_025537-js1cdtwu/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run js1cdtwu errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-5-16672ad91cf6>\", line 160, in train_sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     history = model.fit(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/__autograph_generated_filegx7sttb5.py\", line 73, in tf__call\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _, outputs_ta, _ = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(condition), ag__.ld(body), [ag__.ld(time), ag__.ld(outputs_ta), ag__.ld(decoder_states)]), None, fscope)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: Exception encountered when calling TransliterationSeq2Seq.call().\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[1min user code:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     File \"<ipython-input-4-4e4c3fb073bd>\", line 339, in call  *\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         _, outputs_ta, _ = tf.while_loop(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ValueError: The two structures don't have the same nested structure.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     First structure: type=tuple str=(<tf.Tensor 'while/add_1:0' shape=() dtype=int32>, <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7dede35043d0>, [<tf.Tensor 'while/decoder_layer_1_1/while:4' shape=(None, 256) dtype=float32>, <tf.Tensor 'while/decoder_layer_1_1/while:5' shape=(None, 256) dtype=float32>])\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Second structure: type=list str=[<tf.Tensor 'Const:0' shape=() dtype=int32>, <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7dedec9fbc50>, [<tf.Tensor 'state_h_adapter_1/BiasAdd:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'state_c_adapter_1/BiasAdd:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'state_h_adapter_3/BiasAdd:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'state_c_adapter_3/BiasAdd:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'state_h_adapter_5/BiasAdd:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'state_c_adapter_5/BiasAdd:0' shape=(None, 256) dtype=float32>]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     More specifically: The two structures don't have the same number of elements. First structure: type=list str=[<tf.Tensor 'while/decoder_layer_1_1/while:4' shape=(None, 256) dtype=float32>, <tf.Tensor 'while/decoder_layer_1_1/while:5' shape=(None, 256) dtype=float32>]. Second structure: type=list str=[<tf.Tensor 'state_h_adapter_1/BiasAdd:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'state_c_adapter_1/BiasAdd:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'state_h_adapter_3/BiasAdd:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'state_c_adapter_3/BiasAdd:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'state_h_adapter_5/BiasAdd:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'state_c_adapter_5/BiasAdd:0' shape=(None, 256) dtype=float32>]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Entire first structure:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     (., ., [., .])\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Entire second structure:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     [., ., [., ., ., ., ., .]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Arguments received by TransliterationSeq2Seq.call():\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • inputs=('tf.Tensor(shape=(None, 23), dtype=int32)', 'tf.Tensor(shape=(None, 16), dtype=int32)')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • training=True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: krncfq2d with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_hidden_dim: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_units: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_decoder_units_pair: {'decoder_units': 32, 'encoder_units': 32}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_units: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrent_dropout_rate: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250519_025553-krncfq2d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/krncfq2d' target=\"_blank\">fine-sweep-2</a></strong> to <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/krncfq2d' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/krncfq2d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 106260 training, 10424 dev, and 10517 test examples.\n",
            "  native latin  n\n",
            "0     آؤ   aao  3\n",
            "1     آؤ  aaoo  1\n",
            "2     آؤ   aau  1\n",
            "3     آؤ   aaw  1\n",
            "4     آؤ  aawo  1\n",
            "Epoch 1/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 88ms/step - accuracy: 0.6728 - loss: 1.3436 - val_accuracy: 0.7280 - val_loss: 0.9444\n",
            "Epoch 2/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 89ms/step - accuracy: 0.7360 - loss: 0.9175 - val_accuracy: 0.7741 - val_loss: 0.7640\n",
            "Epoch 3/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 91ms/step - accuracy: 0.7699 - loss: 0.7763 - val_accuracy: 0.8021 - val_loss: 0.6587\n",
            "Epoch 4/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 92ms/step - accuracy: 0.7930 - loss: 0.6881 - val_accuracy: 0.8227 - val_loss: 0.5853\n",
            "Epoch 5/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 92ms/step - accuracy: 0.8101 - loss: 0.6262 - val_accuracy: 0.8369 - val_loss: 0.5284\n",
            "Epoch 6/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 91ms/step - accuracy: 0.8229 - loss: 0.5784 - val_accuracy: 0.8453 - val_loss: 0.4970\n",
            "Epoch 7/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 92ms/step - accuracy: 0.8337 - loss: 0.5411 - val_accuracy: 0.8579 - val_loss: 0.4593\n",
            "Epoch 8/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 92ms/step - accuracy: 0.8427 - loss: 0.5108 - val_accuracy: 0.8661 - val_loss: 0.4346\n",
            "Epoch 9/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 91ms/step - accuracy: 0.8510 - loss: 0.4836 - val_accuracy: 0.8748 - val_loss: 0.4063\n",
            "Epoch 10/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 92ms/step - accuracy: 0.8588 - loss: 0.4584 - val_accuracy: 0.8784 - val_loss: 0.3927\n",
            "Epoch 11/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 92ms/step - accuracy: 0.8658 - loss: 0.4368 - val_accuracy: 0.8828 - val_loss: 0.3777\n",
            "Epoch 12/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 91ms/step - accuracy: 0.8715 - loss: 0.4162 - val_accuracy: 0.8902 - val_loss: 0.3563\n",
            "Epoch 13/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 90ms/step - accuracy: 0.8771 - loss: 0.4000 - val_accuracy: 0.8934 - val_loss: 0.3418\n",
            "Epoch 14/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 91ms/step - accuracy: 0.8809 - loss: 0.3869 - val_accuracy: 0.8965 - val_loss: 0.3322\n",
            "Epoch 15/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 91ms/step - accuracy: 0.8850 - loss: 0.3736 - val_accuracy: 0.9005 - val_loss: 0.3204\n",
            "Epoch 16/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 93ms/step - accuracy: 0.8883 - loss: 0.3622 - val_accuracy: 0.9013 - val_loss: 0.3137\n",
            "Epoch 17/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 90ms/step - accuracy: 0.8906 - loss: 0.3535 - val_accuracy: 0.9036 - val_loss: 0.3054\n",
            "Epoch 18/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 91ms/step - accuracy: 0.8934 - loss: 0.3449 - val_accuracy: 0.9059 - val_loss: 0.3025\n",
            "Epoch 19/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 91ms/step - accuracy: 0.8957 - loss: 0.3387 - val_accuracy: 0.9065 - val_loss: 0.2952\n",
            "Epoch 20/20\n",
            "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 92ms/step - accuracy: 0.8981 - loss: 0.3308 - val_accuracy: 0.9094 - val_loss: 0.2897\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fine-sweep-2</strong> at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/krncfq2d' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/krncfq2d</a><br> View project at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250519_025553-krncfq2d/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run krncfq2d errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-5-16672ad91cf6>\", line 176, in train_sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     pred_dev_sequences = decode_sequences(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                          ^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-4-4e4c3fb073bd>\", line 488, in decode_sequences\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, decoder_states = model.decode_step(current_tokens, decoder_states)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-4-4e4c3fb073bd>\", line 264, in decode_step\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     layer_output, state_h, state_c = rnn_layer(layer_output, initial_state=layer_states)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\", line 6002, in raise_from_not_ok_status\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling LSTMCell.call().\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[1m{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [10424,32], In[1]: [64,256] [Op:MatMul] name: \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Arguments received by LSTMCell.call():\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • inputs=tf.Tensor(shape=(10424, 32), dtype=float32)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • states=('tf.Tensor(shape=(10424, 32), dtype=float32)', 'tf.Tensor(shape=(10424, 32), dtype=float32)')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • training=False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oe5fz5h4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_hidden_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_units: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_decoder_units_pair: {'decoder_units': 128, 'encoder_units': 128}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_units: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrent_dropout_rate: 0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250519_040102-oe5fz5h4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/oe5fz5h4' target=\"_blank\">sunny-sweep-3</a></strong> to <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/oe5fz5h4' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/oe5fz5h4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 106260 training, 10424 dev, and 10517 test examples.\n",
            "  native latin  n\n",
            "0     آؤ   aao  3\n",
            "1     آؤ  aaoo  1\n",
            "2     آؤ   aau  1\n",
            "3     آؤ   aaw  1\n",
            "4     آؤ  aawo  1\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sunny-sweep-3</strong> at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/oe5fz5h4' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/oe5fz5h4</a><br> View project at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250519_040102-oe5fz5h4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run oe5fz5h4 errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-5-16672ad91cf6>\", line 160, in train_sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     history = model.fit(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/__autograph_generated_filegx7sttb5.py\", line 73, in tf__call\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _, outputs_ta, _ = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(condition), ag__.ld(body), [ag__.ld(time), ag__.ld(outputs_ta), ag__.ld(decoder_states)]), None, fscope)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: Exception encountered when calling TransliterationSeq2Seq.call().\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[1min user code:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     File \"<ipython-input-4-4e4c3fb073bd>\", line 339, in call  *\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         _, outputs_ta, _ = tf.while_loop(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ValueError: The two structures don't have the same nested structure.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     First structure: type=tuple str=(<tf.Tensor 'while/add_1:0' shape=() dtype=int32>, <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7dedd40c3ed0>, [<tf.Tensor 'while/decoder_layer_1_1/while:4' shape=(None, 32) dtype=float32>, <tf.Tensor 'while/decoder_layer_2_1/while:4' shape=(None, 32) dtype=float32>, <tf.Tensor 'while/decoder_layer_3_1/while:4' shape=(None, 32) dtype=float32>])\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Second structure: type=list str=[<tf.Tensor 'Const:0' shape=() dtype=int32>, <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7dede0040b10>, [<tf.Tensor 'state_adapter_1/BiasAdd:0' shape=(None, 32) dtype=float32>, <tf.Tensor 'state_adapter_3/BiasAdd:0' shape=(None, 32) dtype=float32>]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     More specifically: The two structures don't have the same number of elements. First structure: type=list str=[<tf.Tensor 'while/decoder_layer_1_1/while:4' shape=(None, 32) dtype=float32>, <tf.Tensor 'while/decoder_layer_2_1/while:4' shape=(None, 32) dtype=float32>, <tf.Tensor 'while/decoder_layer_3_1/while:4' shape=(None, 32) dtype=float32>]. Second structure: type=list str=[<tf.Tensor 'state_adapter_1/BiasAdd:0' shape=(None, 32) dtype=float32>, <tf.Tensor 'state_adapter_3/BiasAdd:0' shape=(None, 32) dtype=float32>]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Entire first structure:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     (., ., [., ., .])\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Entire second structure:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     [., ., [., .]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Arguments received by TransliterationSeq2Seq.call():\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • inputs=('tf.Tensor(shape=(None, 23), dtype=int32)', 'tf.Tensor(shape=(None, 16), dtype=int32)')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • training=True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5ncwk7im with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_hidden_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_units: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_decoder_units_pair: {'decoder_units': 128, 'encoder_units': 128}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_units: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrent_dropout_rate: 0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250519_040112-5ncwk7im</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/5ncwk7im' target=\"_blank\">decent-sweep-4</a></strong> to <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/5ncwk7im' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/5ncwk7im</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 106260 training, 10424 dev, and 10517 test examples.\n",
            "  native latin  n\n",
            "0     آؤ   aao  3\n",
            "1     آؤ  aaoo  1\n",
            "2     آؤ   aau  1\n",
            "3     آؤ   aaw  1\n",
            "4     آؤ  aawo  1\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">decent-sweep-4</strong> at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/5ncwk7im' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/5ncwk7im</a><br> View project at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250519_040112-5ncwk7im/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 5ncwk7im errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-5-16672ad91cf6>\", line 160, in train_sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     history = model.fit(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/__autograph_generated_filegx7sttb5.py\", line 73, in tf__call\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _, outputs_ta, _ = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(condition), ag__.ld(body), [ag__.ld(time), ag__.ld(outputs_ta), ag__.ld(decoder_states)]), None, fscope)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: Exception encountered when calling TransliterationSeq2Seq.call().\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[1min user code:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     File \"<ipython-input-4-4e4c3fb073bd>\", line 339, in call  *\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         _, outputs_ta, _ = tf.while_loop(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ValueError: The two structures don't have the same nested structure.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     First structure: type=tuple str=(<tf.Tensor 'while/add_1:0' shape=() dtype=int32>, <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7dedc779fbd0>, [<tf.Tensor 'while/decoder_layer_1_1/while:4' shape=(None, 256) dtype=float32>, <tf.Tensor 'while/decoder_layer_2_1/while:4' shape=(None, 256) dtype=float32>, <tf.Tensor 'while/decoder_layer_3_1/while:4' shape=(None, 256) dtype=float32>])\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Second structure: type=list str=[<tf.Tensor 'Const:0' shape=() dtype=int32>, <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7dedd4d94310>, [<tf.Tensor 'encoder_layer_1_1/while:4' shape=(None, 256) dtype=float32>, <tf.Tensor 'encoder_layer_2_1/while:4' shape=(None, 256) dtype=float32>]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     More specifically: The two structures don't have the same number of elements. First structure: type=list str=[<tf.Tensor 'while/decoder_layer_1_1/while:4' shape=(None, 256) dtype=float32>, <tf.Tensor 'while/decoder_layer_2_1/while:4' shape=(None, 256) dtype=float32>, <tf.Tensor 'while/decoder_layer_3_1/while:4' shape=(None, 256) dtype=float32>]. Second structure: type=list str=[<tf.Tensor 'encoder_layer_1_1/while:4' shape=(None, 256) dtype=float32>, <tf.Tensor 'encoder_layer_2_1/while:4' shape=(None, 256) dtype=float32>]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Entire first structure:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     (., ., [., ., .])\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Entire second structure:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     [., ., [., .]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Arguments received by TransliterationSeq2Seq.call():\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • inputs=('tf.Tensor(shape=(None, 23), dtype=int32)', 'tf.Tensor(shape=(None, 16), dtype=int32)')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • training=True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c1jwpd2u with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_hidden_dim: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_units: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_decoder_units_pair: {'decoder_units': 32, 'encoder_units': 32}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_units: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrent_dropout_rate: 0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250519_040123-c1jwpd2u</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/c1jwpd2u' target=\"_blank\">cool-sweep-5</a></strong> to <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/c1jwpd2u' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/c1jwpd2u</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 106260 training, 10424 dev, and 10517 test examples.\n",
            "  native latin  n\n",
            "0     آؤ   aao  3\n",
            "1     آؤ  aaoo  1\n",
            "2     آؤ   aau  1\n",
            "3     آؤ   aaw  1\n",
            "4     آؤ  aawo  1\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cool-sweep-5</strong> at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/c1jwpd2u' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/c1jwpd2u</a><br> View project at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250519_040123-c1jwpd2u/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run c1jwpd2u errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-5-16672ad91cf6>\", line 160, in train_sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     history = model.fit(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/__autograph_generated_filegx7sttb5.py\", line 73, in tf__call\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _, outputs_ta, _ = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(condition), ag__.ld(body), [ag__.ld(time), ag__.ld(outputs_ta), ag__.ld(decoder_states)]), None, fscope)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: Exception encountered when calling TransliterationSeq2Seq.call().\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[1min user code:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     File \"<ipython-input-4-4e4c3fb073bd>\", line 339, in call  *\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         _, outputs_ta, _ = tf.while_loop(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ValueError: The two structures don't have the same nested structure.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     First structure: type=tuple str=(<tf.Tensor 'while/add_1:0' shape=() dtype=int32>, <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7dedc5cf2ad0>, [<tf.Tensor 'while/decoder_layer_1_1/while:4' shape=(None, 128) dtype=float32>, <tf.Tensor 'while/decoder_layer_1_1/while:5' shape=(None, 128) dtype=float32>, <tf.Tensor 'while/decoder_layer_2_1/while:4' shape=(None, 128) dtype=float32>, <tf.Tensor 'while/decoder_layer_2_1/while:5' shape=(None, 128) dtype=float32>])\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Second structure: type=list str=[<tf.Tensor 'Const:0' shape=() dtype=int32>, <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7dedc68fae50>, [<tf.Tensor 'state_h_adapter_1/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_1/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_h_adapter_3/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_3/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_h_adapter_5/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_5/BiasAdd:0' shape=(None, 128) dtype=float32>]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     More specifically: The two structures don't have the same number of elements. First structure: type=list str=[<tf.Tensor 'while/decoder_layer_1_1/while:4' shape=(None, 128) dtype=float32>, <tf.Tensor 'while/decoder_layer_1_1/while:5' shape=(None, 128) dtype=float32>, <tf.Tensor 'while/decoder_layer_2_1/while:4' shape=(None, 128) dtype=float32>, <tf.Tensor 'while/decoder_layer_2_1/while:5' shape=(None, 128) dtype=float32>]. Second structure: type=list str=[<tf.Tensor 'state_h_adapter_1/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_1/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_h_adapter_3/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_3/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_h_adapter_5/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_5/BiasAdd:0' shape=(None, 128) dtype=float32>]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Entire first structure:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     (., ., [., ., ., .])\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Entire second structure:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     [., ., [., ., ., ., ., .]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Arguments received by TransliterationSeq2Seq.call():\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • inputs=('tf.Tensor(shape=(None, 23), dtype=int32)', 'tf.Tensor(shape=(None, 16), dtype=int32)')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • training=True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ig93vwfh with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_hidden_dim: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_units: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_decoder_units_pair: {'decoder_units': 32, 'encoder_units': 32}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_units: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrent_dropout_rate: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250519_040133-ig93vwfh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/ig93vwfh' target=\"_blank\">glamorous-sweep-6</a></strong> to <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/sweeps/htolktf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/ig93vwfh' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/ig93vwfh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 106260 training, 10424 dev, and 10517 test examples.\n",
            "  native latin  n\n",
            "0     آؤ   aao  3\n",
            "1     آؤ  aaoo  1\n",
            "2     آؤ   aau  1\n",
            "3     آؤ   aaw  1\n",
            "4     آؤ  aawo  1\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glamorous-sweep-6</strong> at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/ig93vwfh' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3/runs/ig93vwfh</a><br> View project at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250519_040133-ig93vwfh/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ig93vwfh errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-5-16672ad91cf6>\", line 160, in train_sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     history = model.fit(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/__autograph_generated_filegx7sttb5.py\", line 73, in tf__call\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _, outputs_ta, _ = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(condition), ag__.ld(body), [ag__.ld(time), ag__.ld(outputs_ta), ag__.ld(decoder_states)]), None, fscope)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: Exception encountered when calling TransliterationSeq2Seq.call().\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[1min user code:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     File \"<ipython-input-4-4e4c3fb073bd>\", line 339, in call  *\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         _, outputs_ta, _ = tf.while_loop(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ValueError: The two structures don't have the same nested structure.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     First structure: type=tuple str=(<tf.Tensor 'while/add_1:0' shape=() dtype=int32>, <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7dedc1eb7ad0>, [<tf.Tensor 'while/decoder_layer_1_1/while:4' shape=(None, 128) dtype=float32>, <tf.Tensor 'while/decoder_layer_1_1/while:5' shape=(None, 128) dtype=float32>])\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Second structure: type=list str=[<tf.Tensor 'Const:0' shape=() dtype=int32>, <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7dedc33cf8d0>, [<tf.Tensor 'state_h_adapter_1/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_1/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_h_adapter_3/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_3/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_h_adapter_5/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_5/BiasAdd:0' shape=(None, 128) dtype=float32>]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     More specifically: The two structures don't have the same number of elements. First structure: type=list str=[<tf.Tensor 'while/decoder_layer_1_1/while:4' shape=(None, 128) dtype=float32>, <tf.Tensor 'while/decoder_layer_1_1/while:5' shape=(None, 128) dtype=float32>]. Second structure: type=list str=[<tf.Tensor 'state_h_adapter_1/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_1/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_h_adapter_3/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_3/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_h_adapter_5/BiasAdd:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'state_c_adapter_5/BiasAdd:0' shape=(None, 128) dtype=float32>]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Entire first structure:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     (., ., [., .])\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     Entire second structure:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     [., ., [., ., ., ., ., .]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Arguments received by TransliterationSeq2Seq.call():\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • inputs=('tf.Tensor(shape=(None, 23), dtype=int32)', 'tf.Tensor(shape=(None, 16), dtype=int32)')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • training=True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 5 failed runs in a row at start, killing sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val\n"
          ]
        }
      ],
      "source": [
        "# Model creation with dropout support\n",
        "def create_model(input_vocab_size,\n",
        "                target_vocab_size,\n",
        "                embedding_dim,\n",
        "                decoder_hidden_dim,\n",
        "                encoder_units,\n",
        "                decoder_units,\n",
        "                cell_type='lstm',\n",
        "                encoder_layers=1,\n",
        "                decoder_layers=1,\n",
        "                dropout_rate=0.0,\n",
        "                recurrent_dropout_rate=0.0):\n",
        "    \"\"\"\n",
        "    Create and compile a transliteration model.\n",
        "\n",
        "    Args:\n",
        "        input_vocab_size: Size of the input vocabulary\n",
        "        target_vocab_size: Size of the target vocabulary\n",
        "        embedding_dim: Dimension of character embeddings\n",
        "        encoder_units: Number of units in encoder cell\n",
        "        decoder_units: Number of units in decoder cell\n",
        "        cell_type: Type of RNN cell ('rnn', 'lstm', or 'gru')\n",
        "        encoder_layers: Number of layers in the encoder\n",
        "        decoder_layers: Number of layers in the decoder\n",
        "        dropout_rate: Dropout rate after RNN layers\n",
        "        recurrent_dropout_rate: Dropout rate inside RNN cells\n",
        "\n",
        "    Returns:\n",
        "        model: Compiled transliteration model\n",
        "    \"\"\"\n",
        "    # Create inputs\n",
        "    input_seq = Input(shape=(None,), name='input_sequence')\n",
        "    target_seq = Input(shape=(None,), name='target_sequence')\n",
        "\n",
        "    # Create model\n",
        "    model = TransliterationSeq2Seq(\n",
        "        input_vocab_size=input_vocab_size,\n",
        "        target_vocab_size=target_vocab_size,\n",
        "        embedding_dim=embedding_dim,\n",
        "        decoder_hidden_dim=decoder_hidden_dim,\n",
        "        encoder_units=encoder_units,\n",
        "        decoder_units=decoder_units,\n",
        "        cell_type=cell_type,\n",
        "        encoder_layers=encoder_layers,\n",
        "        decoder_layers=decoder_layers,\n",
        "        dropout_rate=dropout_rate,\n",
        "        recurrent_dropout_rate=recurrent_dropout_rate\n",
        "    )\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# WandB setup and hyperparameter sweep\n",
        "def setup_wandb_sweep():\n",
        "    \"\"\"\n",
        "    Setup wandb hyperparameter sweep.\n",
        "\n",
        "    Returns:\n",
        "        sweep_id: ID of the created sweep\n",
        "    \"\"\"\n",
        "    sweep_config = {\n",
        "        'method': 'bayes',  # Bayesian optimization\n",
        "        'metric': {\n",
        "            'name': 'val_accuracy',\n",
        "            'goal': 'maximize'\n",
        "        },\n",
        "        'parameters': {\n",
        "            'embedding_dim': {\n",
        "                'values': [16, 32, 64]\n",
        "            },\n",
        "            'decoder_hidden_dim': {\n",
        "                'values': [16, 32, 64]\n",
        "            },\n",
        "            'encoder_units': {\n",
        "                'values': [32, 64, 128, 256]\n",
        "            },\n",
        "            'decoder_units': {\n",
        "                'values': [32, 64, 128, 256]\n",
        "            },\n",
        "\n",
        "            \"encoder_decoder_units_pair\": {\n",
        "            \"values\": [\n",
        "                {\"encoder_units\": 32, \"decoder_units\": 32},\n",
        "                {\"encoder_units\": 64, \"decoder_units\": 64},\n",
        "                {\"encoder_units\": 128, \"decoder_units\": 128},\n",
        "                {\"encoder_units\": 256, \"decoder_units\": 256}\n",
        "            ]},\n",
        "            'encoder_layers': {\n",
        "                'values': [1, 2, 3]\n",
        "            },\n",
        "            'decoder_layers': {\n",
        "                'values': [1, 2, 3]\n",
        "            },\n",
        "            'cell_type': {\n",
        "                'values': ['lstm', 'gru', 'rnn']\n",
        "            },\n",
        "            'dropout_rate': {\n",
        "                'values': [0.0, 0.2, 0.3]\n",
        "            },\n",
        "            'recurrent_dropout_rate': {\n",
        "                'values': [0.0, 0.1, 0.2]\n",
        "            },\n",
        "            'beam_size': {\n",
        "                'values': [1, 3, 5]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Create sweep\n",
        "    sweep_id = wandb.sweep(sweep_config, project=\"DL_A3\")\n",
        "\n",
        "    return sweep_id\n",
        "\n",
        "\n",
        "# Training function for wandb sweep\n",
        "def train_sweep():\n",
        "    \"\"\"\n",
        "    Training function for wandb sweep.\n",
        "    \"\"\"\n",
        "    # Initialize wandb\n",
        "    run = wandb.init()\n",
        "\n",
        "    # Get wandb config\n",
        "    config = wandb.config\n",
        "\n",
        "    # Load data\n",
        "    train_data, dev_data, test_data = load_dakshina_data()\n",
        "    preprocessed_data = preprocess_data(train_data, dev_data, test_data)\n",
        "\n",
        "    # Create model with config parameters\n",
        "    model = create_model(\n",
        "        input_vocab_size=preprocessed_data['latin_vocab_size'],\n",
        "        target_vocab_size=preprocessed_data['native_vocab_size'],\n",
        "        embedding_dim=config.embedding_dim,\n",
        "        decoder_hidden_dim=config.decoder_hidden_dim,\n",
        "        encoder_units=config.encoder_units,\n",
        "        decoder_units=config.decoder_units,\n",
        "        cell_type=config.cell_type,\n",
        "        encoder_layers=config.encoder_layers,\n",
        "        decoder_layers=config.decoder_layers,\n",
        "        dropout_rate=config.dropout_rate,\n",
        "        recurrent_dropout_rate=config.recurrent_dropout_rate\n",
        "    )\n",
        "\n",
        "    # # Setup callbacks\n",
        "    # callbacks = [\n",
        "    #     WandbCallback(),\n",
        "    #     EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    #     ModelCheckpoint('best_model.h5', save_best_only=True)\n",
        "    # ]\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        [preprocessed_data['train_latin'], preprocessed_data['train_native']],\n",
        "        preprocessed_data['train_native_target'],\n",
        "        validation_data=(\n",
        "            [preprocessed_data['dev_latin'], preprocessed_data['dev_native']],\n",
        "            preprocessed_data['dev_native_target']\n",
        "        ),\n",
        "        epochs=20,\n",
        "        batch_size=64,\n",
        "        # callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Evaluate with beam search\n",
        "    beam_size = config.beam_size\n",
        "\n",
        "    # Decode dev set with beam search\n",
        "    pred_dev_sequences = decode_sequences(\n",
        "        model,\n",
        "        preprocessed_data['dev_latin'],\n",
        "        preprocessed_data['start_token'],\n",
        "        preprocessed_data['end_token'],\n",
        "        preprocessed_data['max_native_len'],\n",
        "        beam_size=beam_size\n",
        "    )\n",
        "\n",
        "    # Remove start/end tokens from the target sequences\n",
        "    true_dev_sequences = [seq[1:-1] for seq in preprocessed_data['dev_native'].tolist()]\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = calculate_accuracy(true_dev_sequences, pred_dev_sequences)\n",
        "\n",
        "    # Log metrics\n",
        "    wandb.log({\n",
        "        'dev_char_accuracy': accuracy['char_accuracy']*100,\n",
        "        'dev_word_accuracy': accuracy['word_accuracy']*100\n",
        "    })\n",
        "\n",
        "    # Convert some examples to text for visual inspection\n",
        "    native_tokenizer = preprocessed_data['native_tokenizer']\n",
        "    latin_tokenizer = preprocessed_data['latin_tokenizer']\n",
        "\n",
        "    # Get sample predictions\n",
        "    sample_idx = np.random.choice(len(pred_dev_sequences), min(10, len(pred_dev_sequences)), replace=False)\n",
        "    samples = []\n",
        "\n",
        "    for idx in sample_idx:\n",
        "        input_text = tokens_to_text([preprocessed_data['dev_latin'][idx].tolist()], latin_tokenizer)[0]\n",
        "        true_text = tokens_to_text([true_dev_sequences[idx]], native_tokenizer)[0]\n",
        "        pred_text = tokens_to_text([pred_dev_sequences[idx]], native_tokenizer)[0]\n",
        "\n",
        "        samples.append({\n",
        "            'input': input_text,\n",
        "            'true': true_text,\n",
        "            'pred': pred_text\n",
        "        })\n",
        "\n",
        "    # Log sample predictions\n",
        "    wandb.log({'samples': wandb.Table(\n",
        "        columns=['Input', 'True', 'Predicted'],\n",
        "        data=[[s['input'], s['true'], s['pred']] for s in samples]\n",
        "    )})\n",
        "\n",
        "    # Clean up\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "# Main script for running the sweep\n",
        "def main():\n",
        "    \"\"\"Main function to run the sweep.\"\"\"\n",
        "    sweep_id = setup_wandb_sweep()\n",
        "    wandb.agent(sweep_id, train_sweep, count=20)  # Run 20 experiments\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV5oW4cxJHDU"
      },
      "source": [
        "e4d0a8c3ccaf2534e9ab91c659e420ba5114533f\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSBKhHWurtqH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNp1FcOmGF99h01F+5+CTN3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}